{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/q1xm4z_j5cgdswpvb5n90pc00000gn/T/ipykernel_1845/1101123491.py:12: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "sns.set()\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "dataset_path = os.path.join(os.getcwd(), \"data\")\n",
    "checkpoint_path = os.path.join(os.getcwd(), \"checkpoint\")\n",
    "\n",
    "device = torch.device(\"mps:0\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/NodeLevelMLP.ckpt...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/NodeLevelGNN.ckpt...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/GraphLevelGraphConv.ckpt...\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/\"\n",
    "# Files to download\n",
    "pretrained_files = [\"NodeLevelMLP.ckpt\", \"NodeLevelGNN.ckpt\", \"GraphLevelGraphConv.ckpt\"]\n",
    "\n",
    "os.makedirs(checkpoint_path, exist_ok = True)\n",
    "\n",
    "for file_name in pretrained_files:\n",
    "    file_path = os.path.join(checkpoint_path, file_name)\n",
    "    if \"/\" in file_name:\n",
    "        os.makedirs(file_path.rsplit(\"/\", 1)[0], exist_ok=True)\n",
    "    if not os.path.isfile(file_path):\n",
    "        file_url = base_url + file_name\n",
    "        print(f\"Downloading {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print(\"There has been an error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class graph_conv_layer(nn.Module):\n",
    "\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super().__init__()\n",
    "        self.projection == nn.Linear(c_in, c_out)\n",
    "\n",
    "    def forward(self, node_feats, adj_matrix):\n",
    "        num_neighbours = adj_matrix.sum(dim = -1, keepdims = True)\n",
    "        node_feats = self.projection(node_feats)\n",
    "        node_feats = torch.bmm(adj_matrix, node_feats) #batc mul far more memory efficient than matmul\n",
    "        node_feats = node_feats/num_neighbours\n",
    "        return node_feats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With one layer, nodes output is the average of itself and its neighbouring nodes however in a gnn we want to allow feature exchange between nodes beyond its neighbours which can be achieved by multiple GCN layers. \n",
    "\n",
    "GCN can lead to same output features if they have same adjacent nodes. One simple option to improve this may be a residual connection buut perhaps a better approach is to use attention.\n",
    "\n",
    "Graph attention layer creates a message for each node using a linear layer/weight matrix. For the attention part it uses the message from the node as a query and the messages to average as both keys and values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, c_in, c_out, num_heads = 1, concat_heads = True, alpha = 0.2):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.concat_heads = concat_heads\n",
    "        if self.concat_heads:\n",
    "            assert c_out % num_heads ==0, \"Number of output features must be a mutliple of number of heads\"\n",
    "\n",
    "        self.projection = nn.Linear(c_in, c_out * num_heads)\n",
    "        self.a == nn.Parameter(torch.Tensor(num_heads, 2 * c_out))\n",
    "        self.leaky_relu = nn.LeakyReLU(alpha)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.project.weight.data, gain = 1.414)\n",
    "        nn.init.xavier_uniform_(self.a.data, gain = 1.414)\n",
    "\n",
    "    def forward(self, node_feats, adj_matrix, print_attn_probs = False):\n",
    "        batch_size, num_nodes = node_feats.size(0), node_feats.size(1)\n",
    "        node_feats = self.projection(node_feats)\n",
    "        node_feats = node_feats.view(batch_size, num_nodes, self.num_heads, -1)\n",
    "        edges = adj_matrix.nonzero(as_tuple = False)\n",
    "        node_feats_flat = node_feats.view(batch_size * num_nodes, self.num_heads, -1)\n",
    "        edge_indices_row = edges[:,0] * num_nodes + edges[:, 1]\n",
    "        edge_indices_col = edges[:, 0] * num_nodes + edges[:, 2]\n",
    "        a_input = torch.cat([\n",
    "            torch.index_select(input = node_feats_flat, index = edge_indices_row, dim = 0),\n",
    "            torch.index_select(input = node_feats_flat, index = edge_indices_col, dim = 0)\n",
    "        ], dim = -1)\n",
    "\n",
    "        #calculate attention MLP output\n",
    "        attn_logits = torch.einsum(\"bhc,hc->bh\", a_input, self.a)\n",
    "        attn_logits = self.leaky_relu(attn_logits)\n",
    "\n",
    "        #map list of vals back into a matrix\n",
    "        attn_matrix = attn_logits.new_zeros(adj_matrix.shape + (self.num_heads,)).fill(9e-15)\n",
    "        attn_matrix[adj_matrix[...,None].repeat(1, 1 ,1, self.num_heads) == 1] = attn_logits.reshape(-1)\n",
    "\n",
    "        #weighted average of attention\n",
    "        attn_probs = F.softmax(attn_matrix)\n",
    "        if print_attn_probs:\n",
    "            print(\"Attention probs\\n\", attn_probs.permute(0, 3, 1, 2))\n",
    "        node_feats = torch.einsum(\"bijh,bjhc->bihc\", attn_probs, node_feats)\n",
    "\n",
    "        #If heads should be concatenated\n",
    "        if self.concat_heads:\n",
    "            node_feats = node_feats.reshape(batch_size, num_nodes, -1)\n",
    "        else:\n",
    "            node_feats = node_feats.mean(dim = 2)\n",
    "\n",
    "        return node_feats\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3367,  0.1288],\n",
      "        [ 0.2345,  0.2303],\n",
      "        [-1.1229, -0.1863]])\n",
      "tensor([[ 2.2082, -0.6380],\n",
      "        [ 0.4617,  0.2674],\n",
      "        [ 0.5349,  0.8094]])\n",
      "tensor([[ 2.2082,  0.4617,  0.5349],\n",
      "        [-0.6380,  0.2674,  0.8094]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5698, -0.1520],\n",
       "        [ 0.5379, -0.0265],\n",
       "        [ 0.2246,  0.5556]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
